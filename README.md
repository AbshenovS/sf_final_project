## Финальный проект для соревнавания от Skillfactory по прогнозированию стоимости автомобиля по характеристикам

#### Ссылка на соревнование - https://www.kaggle.com/c/sf-dst-car-price-prediction
#### Проект был сделан индивидуально, имя команды - Sagyndyk Abshenov.
Решение в файле `sf_car_price.ipynb` \
Решение может быть полностью воспроизводимо если запустить ноутбук в **Kaggle**. Нужно подключить ниже укаженные датасеты и GPU accelrator:
&nbsp;
![gpu_kaggle](/gpu_on.png?raw=true "gpu")

## Тренировачные данные
По правилам соревнования
> - *Разрешено использовать внешние данные. (но их источник должен быть публичным и доступен всем участникам соревнования)*

Я использовал следующие публичные датасеты: 
- https://www.kaggle.com/sokolovaleks/parsing-all-moscow-auto-ru-09-09-2020
- https://www.kaggle.com/rzabolotin/auto-ru-car-ads-parsed

## Результат в соревновании на Kaggle.
4-место (2-место на потоке) в Лидерборде на время сдачи проекта. MAPE - 9.24810.
&nbsp;
![score](/score.png?raw=true "my_score")

## Обработка и генерация признаков
#### Категориальные призанки
Были обработаны. У всех признаков(кроме model_name) все значения в тесте представлены и в трейне.
Сгенерировал комбинации разных признаков, существенного роста не дали в валидации. Новый признак:
- *'tms_pri'*   -  комбинация трансмиссии и привода 

Все категориальные признаки были энкодированы в числовые значения
#### Числовые призанки
Новые признаки:
- *'bodyType_mean'*  - средняя цена для каждого типа
- *'brand_mean'*  - средняя цена для каждого бренда автомобилей
- *'mil_per_year'*  - средний пробег в году
- *'age_of_model'*  - разница между годом производства и выхода модели
- *11 полинимальных признаков на основе числовых признаков*

Все числовые признаки были отмасштабированы с помощью StandardScaler (у MinMaxScaler результат хуже)
#### В итоге для обучения использовались 32 признаков

## Библиотеки
Были использованы различные библиотеки: 

*pandas, numpy, sklearn(preprocessing, model_selection, ensemble, etc.), catboost, xgboost, lightgbm, tqdm*

## Стакинг
Проводились стакинги с разными мета моделями. Лучший результат показал StackingRegressor c xgb regressor и lgbm regressor (с подобранными гиперпареметрами) в качестве базовых моделей и c дефолтным RidgeCV в качестве финального моделя.


# Заключительные выводы
Проект очень сильно помог закрепить полученные знания и почуствовать настящую работу аналитика данных. \
В ходе работы над проектом я часто обращался к материалам на платформе Skillfactory и очень много гуглил. Изучал разные алгоритмы и с их помощью проверял свои гипотезы. \
К сожалению я не смог уделить много времени к соревнованию, в перспективе можно было бы значительно улучшить результат 
### Возможные дальнейшие улучшения: 
- генерация и проверка еще многих других признаков
- подбор гиперпараметров для использованных градиентных бустингов
- попробовать другие методы стакинга
